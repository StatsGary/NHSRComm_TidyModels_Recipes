print(factors); print(numbers); print(characters)
# Partition into training and hold out test / validation sample
set.seed(123)
split <- rsample::initial_split(strand_pat, prop=3/4)
train_data <- rsample::training(split)
test_data <- rsample::testing(split)
View(train_data)
stranded_rec <-
recipe(stranded_class ~ ., data=train_data) %>%
# The stranded class is what we are trying to predict and we are using the training data
step_date(admit_date, features = c("dow", "month")) %>%
#Recipes step_date allows for additional features to be created from the date
step_rm(admit_date) %>%
#Remove the date, as we have created features off of it, if left in the dreaded multicolinearity may be present
themis::step_upsample(stranded_class, over_ratio = as.numeric(upsample_ratio)) %>%
#SMOTE recipe step to upsample the minority class i.e. stranded patients
step_dummy(all_nominal(), -all_outcomes()) %>%
#Automatically created dummy variables for all categorical variables (nominal)
step_zv(all_predictors()) %>%
#Get rid of features that have zero variance
step_normalize(all_predictors()) #ML models train better when the data is centered and scaled
print(stranded_rec) #Terminology is to use recipe
View(stranded_rec)
lr_mod <-
parsnip::logistic_reg() %>%
set_engine("glm")
print(lr_mod)
# Create model workflow
strand_wf <-
workflow() %>%
add_model(lr_mod) %>%
add_recipe(stranded_rec)
print(strand_wf)
# Create the model fit
strand_fit <-
strand_wf %>%
fit(data = train_data)
strand_fitted <- strand_fit %>%
pull_workflow_fit() %>%
tidy()
print(strand_fitted)
# Add significance column to tibble using mutate
strand_fitted <- strand_fitted  %>%
mutate(Significance = ifelse(p.value < 0.05, "Significant", "Insignificant")) %>%
arrange(desc(p.value))
#Create a ggplot object to visualise significance
plot <- strand_fitted %>%
ggplot(data = strand_fitted, mapping = aes(x=term, y=p.value, fill=Significance)) +
geom_col() + theme(axis.text.x = element_text(
face="bold", color="#0070BA",
size=8, angle=90)
) + labs(y="P value", x="Terms",
title="P value significance chart",
subtitle="A chart to represent the significant variables in the model",
caption="Produced by Gary Hutson")
#print("Creating plot of P values")
#print(plot)
plotly::ggplotly(plot)
#print(ggplotly(plot))
#ggsave("Figures/p_val_plot.png", plot) #Save the plot
class_pred <- predict(strand_fit, test_data) #Get the class label predictions
prob_pred <- predict(strand_fit, test_data, type="prob") #Get the probability predictions
lr_predictions <- data.frame(class_pred, prob_pred) %>%
setNames(c("LR_Class", "LR_NotStrandedProb", "LR_StrandedProb")) #Combined into tibble and rename
stranded_preds <- test_data %>%
bind_cols(lr_predictions)
print(tail(lr_predictions))
roc_plot <-
stranded_preds %>%
roc_curve(truth = stranded_class, LR_NotStrandedProb) %>%
autoplot
print(roc_plot)
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded")
print(cm)
# Add significance column to tibble using mutate
strand_fitted <- strand_fitted  %>%
mutate(Significance = ifelse(p.value < 0.05, "Significant", "Insignificant")) %>%
arrange(desc(p.value))
#Create a ggplot object to visualise significance
plot <- strand_fitted %>%
ggplot(data = strand_fitted, mapping = aes(x=term, y=p.value, fill=Significance)) +
geom_col() + theme(axis.text.x = element_text(
face="bold", color="#0070BA",
size=8, angle=90)
) + labs(y="P value", x="Terms",
title="P value significance chart",
subtitle="A chart to represent the significant variables in the model",
caption="Produced by Gary Hutson")
#print("Creating plot of P values")
#print(plot)
plotly::ggplotly(plot) + theme_classic()
#print(ggplotly(plot))
#ggsave("Figures/p_val_plot.png", plot) #Save the plot
# Add significance column to tibble using mutate
strand_fitted <- strand_fitted  %>%
mutate(Significance = ifelse(p.value < 0.05, "Significant", "Insignificant")) %>%
arrange(desc(p.value))
#Create a ggplot object to visualise significance
plot <- strand_fitted %>%
ggplot(data = strand_fitted, mapping = aes(x=term, y=p.value, fill=Significance)) +
geom_col() + theme(axis.text.x = element_text(
face="bold", color="#0070BA",
size=8, angle=90)
) + labs(y="P value", x="Terms",
title="P value significance chart",
subtitle="A chart to represent the significant variables in the model",
caption="Produced by Gary Hutson")
#print("Creating plot of P values")
#print(plot)
plotly::ggplotly(plot)
#print(ggplotly(plot))
#ggsave("Figures/p_val_plot.png", plot) #Save the plot
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded")
print(cm)
View(stranded_preds)
View(stranded_preds)
library(ConfusionTableR)
cm_plot <- ConfusionTableR::binary_visualiseR(stranded_preds$stranded_class,
stranded_preds$LR_Class)
# Flatten to store in database
#Stored confusion matrix
cm_results <- ConfusionTableR::binary_class_cm(cm)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
)
# Flatten to store in database
#Stored confusion matrix
cm_results <- ConfusionTableR::binary_class_cm(cm)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded",
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Long Waiting Patient in an Inpatient Setting",
text_col= "black"))
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded",
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Long Waiting Patient in an Inpatient Setting")
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded",
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Setting")
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Setting")
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class,
positive="Stranded")
print(cm)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black")
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_lbl_size = 0.5,
cm_stat_size = 1)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_lbl_size = 0.6,
cm_stat_size = 1)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_lbl_size = 1,
cm_stat_size = 1)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_lbl_size = 1,
cm_stat_size = 2)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_lbl_size = 2,
cm_stat_size = 2)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 2)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 0.5)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 0.9)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1,
round_dig = 2)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1,
round_dig = 5)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1,
round_dig = 2)
library(ConfusionTableR)
cm <- ConfusionTableR::binary_visualiseR(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
class_label1 = "Not Stranded",
class_label2 = "Stranded",
quadrant_col1 = "#28ACB4",
quadrant_col2 = "#4397D2",
custom_title = "Stranded Patient Confusion Matrix",
text_col= "black",
cm_stat_size = 1.2,
round_dig = 2)
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
View(cm_binary_class)
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
# Expose the record level confusion matrix
cm_binary_class$record_level_cm
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
# Expose the record level confusion matrix
glimpse(cm_binary_class$record_level_cm)
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
# Expose the record level confusion matrix
glimpse(cm_binary_class$record_level_cm)
library(caret)
cm <- caret::confusionMatrix(stranded_preds$stranded_class,
stranded_preds$LR_Class)
print(cm)
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class,
positive = "Stranded")
cm_binary_class <- ConfusionTableR::binary_class_cm(
train_labels = stranded_preds$stranded_class,
truth_labels = stranded_preds$LR_Class)
# Expose the record level confusion matrix
glimpse(cm_binary_class$record_level_cm)
save.image(file="Data/stranded_data.rdata")
load(file="Data/stranded_data.rdata")
set.seed(123)
#Set a random seed for replication of results
ten_fold <- vfold_cv(train_data, v=10)
set.seed(123)
lr_fit_rs <-
strand_wf %>%
fit_resamples(ten_fold)
# To collect the resmaples you need to call collect_metrics to average out the accuracy for that model
collected_mets <- tune::collect_metrics(lr_fit_rs)
print(collected_mets)
# Now I can compare the accuracy from the previous test set I had already generated a confusion matrix for
accuracy_resamples <- collected_mets$mean[1] * 100
accuracy_validation_set <- as.numeric(cm$overall[1] * 100)
print(cat(paste0("The true accuracy of the model is between the resample testing:",
round(accuracy_resamples,2), "\nThe validation sample: ",
round(accuracy_validation_set,2), ".")))
rf_mod <-
rand_forest(trees=500) %>%
set_engine("ranger") %>%
set_mode("classification")
print(rf_mod)
rf_fit <-
rf_mod %>%
fit(stranded_class ~ ., data = train_data)
install.packages("ranger")
rf_fit <-
rf_mod %>%
fit(stranded_class ~ ., data = train_data)
print(rf_fit)
#Create workflow step
rf_wf <-
workflow() %>%
add_model(rf_mod) %>%
add_formula(stranded_class ~ .) #The predictor is contained in add_formula method
set.seed(123)
rf_fit_rs <-
rf_wf %>%
fit_resamples(ten_fold)
print(rf_fit_rs)
# Collect the metrics using another model with resampling
rf_resample_mean_preds <- tune::collect_metrics(rf_fit_rs)
print(rf_resample_mean_preds)
tune_tree <-
decision_tree(
cost_complexity = tune(), #tune() is a placeholder for an empty grid
tree_depth = tune() #we will fill these in the next section
) %>%
set_engine("rpart") %>%
set_mode("classification")
print(tune_tree)
grid_tree_tune <- grid_regular(dials::cost_complexity(),
dials::tree_depth(),
levels = 10)
print(head(grid_tree_tune,20))
all_cores <- parallel::detectCores(logical = FALSE)-1
print(all_cores)
#Registers all cores and subtracts one, so you have some time to work
cl <- makePSOCKcluster(all_cores)
print(cl)
#Makes an in memory cluster to utilise your cores
registerDoParallel(cl)
#Registers that we want to do parallel processing
set.seed(123)
tree_wf <- workflow() %>%
add_model(tune_tree) %>%
add_formula(stranded_class ~ .)
# Make the decision tree workflow - always postfix with wf for convention
# Add the registered model
# Add the formula of the outcome class you are predicting against all IVs
tree_pred_tuned <-
tree_wf %>%
tune::tune_grid(
resamples = ten_fold, #This is the 10 fold cross validation variable we created earlier
grid = grid_tree_tune #This is the tuning grid
)
tune_plot <- tree_pred_tuned %>%
collect_metrics() %>% #Collect metrics from tuning
mutate(tree_depth = factor(tree_depth)) %>%
ggplot(aes(cost_complexity, mean, color = tree_depth)) +
geom_line(size = 1, alpha = 0.7) +
geom_point(size = 1.5) +
facet_wrap(~ .metric, scales = "free", nrow = 2) +
scale_x_log10(labels = scales::label_number()) +
scale_color_viridis_d(option = "plasma", begin = .9, end = 0) + theme_minimal()
print(tune_plot)
ggsave(filename="Figures/hyperparameter_tree.png", tune_plot)
# To get the best ROC - area under the curve value we will use the following:
tree_pred_tuned %>%
tune::show_best("roc_auc")
# Select the best tree
best_tree <- tree_pred_tuned %>%
tune::select_best("roc_auc")
print(best_tree)
final_wf <-
tree_wf %>%
finalize_workflow(best_tree) #Finalise workflow passes in our best tree
print(final_wf)
final_tree_pred <-
final_wf %>%
fit(data = train_data)
print(final_tree_pred)
plot <- final_tree_pred %>%
pull_workflow_fit() %>%
vip(aesthetics = list(color = "black", fill = "#26ACB5")) + theme_minimal()
print(plot)
ggsave("Figures/VarImp.png", plot)
# Create the final prediction
final_fit <-
final_wf %>%
last_fit(split)
final_fit_fitted_metrics <- final_fit %>%
collect_metrics()
print(final_fit_fitted_metrics)
#Create the final predictions
final_fit_predictions <- final_fit %>%
collect_predictions()
print(final_fit_predictions)
roc_plot <- final_fit_predictions %>%
roc_curve(stranded_class, `.pred_Not Stranded`) %>%
autoplot()
print(roc_plot)
ggsave(filename = "Figures/tuned_tree.png", plot=roc_plot)
args(decision_tree)
args(logistic_reg)
args(rand_forest)
